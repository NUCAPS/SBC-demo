{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e481a14",
   "metadata": {},
   "source": [
    "# Visualizing NOAA satellite data from the cloud\n",
    "\n",
    "This very short tutorial will show the basic steps to accessing GOES-16 data on AWS and make an image of the [Sandwich RGB](https://www.star.nesdis.noaa.gov/goes/documents/SandwichProduct.pdf)!\n",
    "\n",
    "The main steps will be:\n",
    "* Import relevant packages\n",
    "* Search cloud repositories for the data we want\n",
    "* Import the data into memory\n",
    "* Make a plot of the sandwich product\n",
    "\n",
    "If you have never coded in Python before, this will probably be fast but I can provide resources to more beginner friendly tools.\n",
    "\n",
    "We will use three packages for this project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd526993",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import s3fs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a105f2e2",
   "metadata": {},
   "source": [
    "The package s3fs is file interface for Amazon S3 (Simple Storage Service) buckets, so you can browse and search for data. NOAA's Open Data Dissemination (NODD) program is increasing access to satellite data, including GOES and JPSS. In this tutiral, we'll look at [https://registry.opendata.aws/noaa-goes/](GOES-16 Mesoscale data in S3).\n",
    "\n",
    "First, we have to initialize the filesystem. We pass in the keyword anon because we are not going to pass any login information since the data are public."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3134236e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = s3fs.S3FileSystem(anon=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4ad4c6",
   "metadata": {},
   "source": [
    "You can manually browse the contents of the S3 bucket using the link above, or you can search in the command line. The S3 bucket is named 'noaa-goes16,' and using s3fs's ls command (we'll only print the first 5 entries for brevity):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13b1eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs.ls('noaa-goes16')[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ca1927",
   "metadata": {},
   "source": [
    "We can repeat the search above by extending the argument from 'noaa-goes16' to 'noaa-goes16/ABI-L1b-RadM' and running the command again. To save some time, let's construct the full path below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e76126",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'noaa-goes16'\n",
    "product_name = 'ABI-L1b-RadM'\n",
    "year = 2022\n",
    "doy = 285\n",
    "hour = 20\n",
    "\n",
    "path = bucket_name + '/' + product_name + '/' + str(year) + '/' + str(doy).zfill(3) + '/' + str(hour).zfill(2) + '/'\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbeba37",
   "metadata": {},
   "source": [
    "Since we're looking at the mesosector scan, this search will still yield a lot of results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bec2014",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = fs.ls(path)\n",
    "print(files[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1855e3",
   "metadata": {},
   "source": [
    "If you've seen satellite data files before, you'll know they have long filenames. Let's break it down:\n",
    "\n",
    "\\[sensor and product name\\]-\\[scan sector\\]_\\[satellite\\]_s\\[scan start time\\]_e\\[scan end time\\]_c\\[creation time\\].nc\n",
    "\n",
    "To save a little bit of time, let's cheat a bit and only work with the first available time stamp (s20222852000281). The sandwich product takes the difference of ABI channels 3 and 13. The snippet of code below will search all the files and only keep the ones that have 'C03' or 'C13' and the start time 's20222852000281'.\n",
    "\n",
    "I'm using a list comprehension, which is a shorter way of writing a loop. For reference, the original loop is commented out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ba13c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Long form of writing a loop\n",
    "# for file in files:\n",
    "#     if ('C01_G16_s20222852000281' in file) | ('C13_G16_s20222852000281'):\n",
    "#         print(file)\n",
    "\n",
    "matches = [file for file in files if ('C03_G16_s20222852000281' in file) | ('C13_G16_s20222852000281' in file)]\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e366c70c",
   "metadata": {},
   "source": [
    "Now that we have found our files in the satellite data \"haystack\" we can finally open them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837c8444",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_obj_ch3 = fs.open(matches[0], mode='rb')\n",
    "remote_obj_ch13 = fs.open(matches[1], mode='rb')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4b773a",
   "metadata": {},
   "source": [
    "We will need to use xarray to read/interpret the netCDF file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36afcbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "abi_ch3 = xr.open_dataset(remote_obj_ch3, engine='h5netcdf')\n",
    "abi_ch13 = xr.open_dataset(remote_obj_ch13, engine='h5netcdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd3dc66",
   "metadata": {},
   "source": [
    "We can print the header information to see the file contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f513b260",
   "metadata": {},
   "outputs": [],
   "source": [
    "abi_ch3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54196bce",
   "metadata": {},
   "source": [
    "We can learn a lot about the file from the header. For example, the file dimensions are 1000 x 1000, there's a useful variable named Rad (for Radiance), and the x and y coordinates in the geostationary projection. Let's preview what the image will look like using matplotlib and imshow. You can use packages like cartopy to plot onto different map projections, but to keep today's tutorial short we'll just look at the raw image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31eeb78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[4,4])\n",
    "plt.imshow(abi_ch3.Rad)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707e6082",
   "metadata": {},
   "source": [
    "Our goal is to create a sandwich product, which combines ABI channel 3 and channel 13 radiances. First, let's extract the radiances from the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e622e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "C13 = abi_ch13.Rad.values\n",
    "C03 = abi_ch3.Rad.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0542b5",
   "metadata": {},
   "source": [
    "We need to make sure both are the same resolution, but unfortunately they are not. Channel 3 is 1 km and Channel 13 is 2 km. You can use the shape command to check the array size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6107f60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "C13.shape, C03.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dbb4af",
   "metadata": {},
   "source": [
    "There are many techniques to change the data reoslution, but a fast and simple way to change the gridding to skip every other pixel. Python can skip indices using the double colons (::) followed by an integer. We'll overwrite the original variable with this new smaller resolution variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070a6237",
   "metadata": {},
   "outputs": [],
   "source": [
    "C03 = C03[::2, ::2]\n",
    "C03.shape, abi_ch13.Rad.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ce4af2",
   "metadata": {},
   "source": [
    "Now that the data are the same shape, we can difference them to create the sandwich product:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510264cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sandwich = C03 - C13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cf94a1",
   "metadata": {},
   "source": [
    "Finally, we'll make a plot of our hard work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88f3762",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[4,4])\n",
    "plt.imshow(sandwich, cmap=plt.get_cmap(\"terrain\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bac28ec",
   "metadata": {},
   "source": [
    "# Summary\n",
    "Through this tutorial, we can see first hand how easy it is to access data from AWS. NOAA is adding more datasets to AWS. JPSS will initially add sounding data from CrIS and ATMS in addition to other products. One caveat is that AWS data is not guaranteed to be operational. However, it is an excellent point of data access for retrospective analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "cf7046c951e869187a5b139c4d96f415dd22efc85b0b4734f037abe763c2d370"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
